{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Train A Shape Classifier Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "train_data_root = \"../datasets/train\"\n",
    "test_data_root = \"../datasets/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['circle', 'diamond', 'triangle']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations (including resizing and normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale (black and white images)\n",
    "    transforms.Resize((64, 64)),  # Resize images to 64x64 pixels\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the images (mean=0.5, std=0.5 for grayscale)\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = datasets.ImageFolder(root=train_data_root, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_data_root, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Check class names (optional)\n",
    "print(f'Classes: {train_dataset.classes}')\n",
    "\n",
    "# 2. Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1) #tenshor shape: (batch_size, 1, 64, 64) to tensor shape: (batch_size, 16, 32, 32)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) #tenshor shape: (batch_size, 16, 32, 32) to tensor shape: (batch_size, 32, 16, 16)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # 3 classes: circle, triangle, rectangle\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))   # First Conv Layer\n",
    "        x = F.max_pool2d(x, 2)      # Max Pooling\n",
    "        x = F.relu(self.conv2(x))   # Second Conv Layer\n",
    "        x = F.max_pool2d(x, 2)      # Max Pooling\n",
    "        x = x.view(x.size(0), -1)   # Flatten\n",
    "        x = F.relu(self.fc1(x))     # Fully Connected Layer 1\n",
    "        x = self.fc2(x)             # Fully Connected Layer 2 (output)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 1.0970, Accuracy: 35.14%\n",
      "Epoch [2/15], Loss: 1.0002, Accuracy: 48.71%\n",
      "Epoch [3/15], Loss: 0.8688, Accuracy: 59.29%\n",
      "Epoch [4/15], Loss: 0.6680, Accuracy: 73.29%\n",
      "Epoch [5/15], Loss: 0.4369, Accuracy: 85.00%\n",
      "Epoch [6/15], Loss: 0.2401, Accuracy: 92.57%\n",
      "Epoch [7/15], Loss: 0.1643, Accuracy: 94.43%\n",
      "Epoch [8/15], Loss: 0.0973, Accuracy: 97.29%\n",
      "Epoch [9/15], Loss: 0.0554, Accuracy: 99.00%\n",
      "Epoch [10/15], Loss: 0.0286, Accuracy: 99.71%\n",
      "Epoch [11/15], Loss: 0.0173, Accuracy: 100.00%\n",
      "Epoch [12/15], Loss: 0.0118, Accuracy: 100.00%\n",
      "Epoch [13/15], Loss: 0.0062, Accuracy: 100.00%\n",
      "Epoch [14/15], Loss: 0.0043, Accuracy: 100.00%\n",
      "Epoch [15/15], Loss: 0.0032, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 - Precision: 0.6214, Recall: 0.7111, F1-score: 0.6632\n",
      "Class 1 - Precision: 0.6809, Recall: 0.6154, F1-score: 0.6465\n",
      "Class 2 - Precision: 0.9515, Recall: 0.9245, F1-score: 0.9378\n",
      "Macro Average - Precision: 0.7512, Recall: 0.7503, F1-score: 0.7492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    all_labels = [] \n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    #Calculate precision, recall, and F1-score for each class\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "\n",
    "    def safe_iter(x):\n",
    "        #if salar, covnert to 1-element list for iteration\n",
    "        if np.isscalar(x):\n",
    "            return [x]\n",
    "        return x\n",
    "    precision = safe_iter(precision)\n",
    "    recall = safe_iter(recall)\n",
    "    f1 = safe_iter(f1)\n",
    "\n",
    "    for i, (p, r ,f) in enumerate(zip(precision, recall, f1)):\n",
    "        print(f'Class {i} - Precision: {p:.4f}, Recall: {r:.4f}, F1-score: {f:.4f}')\n",
    "    \n",
    "    #Calculate and print overall macro averages\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "    print(f'Macro Average - Precision: {precision_macro:.4f}, Recall: {recall_macro:.4f}, F1-score: {f1_macro:.4f}')\n",
    "\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Show Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Class names matching your dataset folder order\n",
    "class_names = ['circle', 'diamond', 'triangle']\n",
    "def show_prediction(model, image):\n",
    "    model.eval()\n",
    "\n",
    "    #Add batch dimension if missing\n",
    "    if image.dim() == 3:\n",
    "        image = image.unsqueeze(0) #shape [1, C, H, W]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image.to(device))\n",
    "        probs = F.softmax(outputs, dim=1) #convert logits to probabilities\n",
    "        conf, pred_idx = torch.max(probs, 1)\n",
    "\n",
    "    #Convert tensor to CPU numpy array for plotting\n",
    "    img_np = image.squeeze().cpu().numpy()\n",
    "\n",
    "    #Plot Image\n",
    "    plt.imshow(img_np, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Prepare texit with prediction and confidence %\n",
    "    label = class_names[pred_idx.item()]\n",
    "    confidence = conf.item() * 100\n",
    "    title = f'Predicted: {label} ({confidence:.2f}%)'\n",
    "    plt.title(title)\n",
    "\n",
    "image, label = test_dataset[298]\n",
    "show_prediction(model, image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

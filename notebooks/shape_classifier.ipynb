{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Train A Shape Classifier Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "train_data_root = \"../datasets/train\"\n",
    "test_data_root = \"../datasets/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['circle', 'diamond', 'triangle']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations (including resizing and normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale (black and white images)\n",
    "    transforms.Resize((64, 64)),  # Resize images to 64x64 pixels\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the images (mean=0.5, std=0.5 for grayscale)\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = datasets.ImageFolder(root=train_data_root, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_data_root, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Check class names (optional)\n",
    "print(f'Classes: {train_dataset.classes}')\n",
    "\n",
    "# 2. Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # 3 classes: circle, triangle, rectangle\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))   # First Conv Layer\n",
    "        x = F.max_pool2d(x, 2)      # Max Pooling\n",
    "        x = F.relu(self.conv2(x))   # Second Conv Layer\n",
    "        x = F.max_pool2d(x, 2)      # Max Pooling\n",
    "        x = x.view(x.size(0), -1)   # Flatten\n",
    "        x = F.relu(self.fc1(x))     # Fully Connected Layer 1\n",
    "        x = self.fc2(x)             # Fully Connected Layer 2 (output)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 0 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([32, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, epochs=15)"
   ]
  },
  {
<<<<<<< Updated upstream
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
=======
   "cell_type": "code",
   "execution_count": 4,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 1.0506, Accuracy: 42.71%\n",
      "Epoch [2/15], Loss: 0.9665, Accuracy: 51.00%\n",
      "Epoch [3/15], Loss: 0.8574, Accuracy: 60.71%\n",
      "Epoch [4/15], Loss: 0.7313, Accuracy: 68.00%\n",
      "Epoch [5/15], Loss: 0.5609, Accuracy: 79.14%\n",
      "Epoch [6/15], Loss: 0.3545, Accuracy: 87.86%\n",
      "Epoch [7/15], Loss: 0.2278, Accuracy: 93.71%\n",
      "Epoch [8/15], Loss: 0.1321, Accuracy: 97.29%\n",
      "Epoch [9/15], Loss: 0.0870, Accuracy: 98.29%\n",
      "Epoch [10/15], Loss: 0.0439, Accuracy: 99.57%\n",
      "Epoch [11/15], Loss: 0.0244, Accuracy: 99.86%\n",
      "Epoch [12/15], Loss: 0.0164, Accuracy: 100.00%\n",
      "Epoch [13/15], Loss: 0.0105, Accuracy: 100.00%\n",
      "Epoch [14/15], Loss: 0.0067, Accuracy: 100.00%\n",
      "Epoch [15/15], Loss: 0.0055, Accuracy: 100.00%\n"
     ]
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 300\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader):\n",
    "    \"\"\"Print the Precision, Recall and F1-score for the trained model\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Show Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0, Precision: 0.5856, Recall: 0.7222, F1-score: 0.6468\n",
      "Class 1, Precision: 0.6915, Recall: 0.6250, F1-score: 0.6566\n",
      "Class 2, Precision: 0.9263, Recall: 0.8302, F1-score: 0.8756\n",
      "Overall (Macro) Precision=0.7345, Recall=0.7258, F1-Score=0.7263\n"
     ]
    }
   ],
   "source": [
<<<<<<< Updated upstream
=======
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate precision, recall and f1-score for each class\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "    \n",
    "    def safe_iter(x):\n",
    "        # If scalar, convert to 1-element list for iteration\n",
    "        if np.isscalar(x):\n",
    "            return [x]\n",
    "        return x\n",
    "\n",
    "    precision = safe_iter(precision)\n",
    "    recall = safe_iter(recall)\n",
    "    f1 = safe_iter(f1)\n",
    "\n",
    "    for i, (p, r, f) in enumerate(zip(precision, recall, f1)):\n",
    "        print(f'Class {i}, Precision: {p:.4f}, Recall: {r:.4f}, F1-score: {f:.4f}')\n",
    "\n",
    "    # Calculate and print overall (macro) averages\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "    print(f'Overall (Macro) Precision={precision_macro:.4f}, Recall={recall_macro:.4f}, F1-Score={f1_macro:.4f}')\n",
    "\n",
    "# Call test function after training\n",
    "test(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Show Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Class names matching your dataset folders order\n",
    "class_names = ['circle', 'diamond', 'triangle']\n",
    "\n",
>>>>>>> Stashed changes
    "def show_prediction(model, image):\n",
    "    \"\"\"Pass the image to the model and overlay the predicted shape and confidence on the input\n",
    "    image and display it\n",
    "    \"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
